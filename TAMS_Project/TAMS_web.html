<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Nerfies: Deformable Neural Radiance Fields</title>
  <link rel="stylesheet" href="style.css">
  <script src="script.js" defer></script>
  <style>
    .hero-body {
      padding: 2rem 1.5rem;
    }

    .custom-box {
      background-color: #f8f9fa;
      border-radius: 50px;
      padding: 20px;
      text-align: center;
      margin: 20px 0;
    }

    .custom-box a {
      margin: 0 10px;
    }

    .authors {
      color: #1E90FF;
      text-align: center;
    }

    .section {
      padding-top: 2rem;
      padding-bottom: 2rem;
    }
  </style>
</head>

<body>
  <section class="section">
    <div class="container is-max-desktop content">
      <h1 class="title">Nerfies: Deformable Neural Radiance Fields</h1>
    </div>
  </section>

  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop content">
        <p class="authors">Keunhong Park, Utkarsh Sinha, Jonathan T. Barron, Sofien Bouaziz, Dan B Goldman, Steven M. Seitz, Ricardo Martin-Brualla</p>
        <p class="authors">University of Washington, Google Research</p>
      </div>
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop content">
      <div class="custom-box">
        <a href="https://keunhong.com/publication/nerfies/nerfies-paper.pdf" class="button is-link">Paper</a>
        <a href="https://youtu.be/0oG_kwOVGoI" class="button is-link">Video</a>
        <a href="https://github.com/google/nerfies" class="button is-link">Code</a>
        <a href="https://github.com/google/nerfies" class="button is-link">Data</a>
      </div>
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop content">
      <div class="video-container">
        <iframe width="560" height="315" src="https://www.youtube.com/embed/0oG_kwOVGoI" frameborder="0" allowfullscreen></iframe>
      </div>
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop content">
      <h2 class="title is-3">Abstract</h2>
      <p>
        We present Nerfies, a method for capturing and modeling casual videos of complex, non-rigidly deforming scenes with a neural
        radiance field. Our method takes a video captured from a single, handheld camera, and is able to both reconstruct the observed
        scene and render novel views of the scene from unobserved viewpoints. This is achieved by jointly optimizing a scene
        model and the camera parameters, while also optimizing a deformation field that models the observed scene as a
        canonical, rigid scene plus non-rigid deformations. Our method operates on casual videos, and does not require
        pre-computed optical flow, image correspondences, or multi-view stereo. We show that our method can model a variety of
        scenes, including people talking, people dancing, and animals moving.
      </p>
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop content">
      <h2 class="title is-3">BibTeX</h2>
      <pre class="box"><code>@article{park2021nerfies,
  author    = {Park, Keunhong and Sinha, Utkarsh and Barron, Jonathan T. and Bouaziz, Sofien and Goldman, Dan B and Seitz, Steven M. and Martin-Brualla, Ricardo},
  title     = {Nerfies: Deformable Neural Radiance Fields},
  journal   = {ICCV},
  year      = {2021},
}</code></pre>
    </div>
  </section>
</body>

</html>
